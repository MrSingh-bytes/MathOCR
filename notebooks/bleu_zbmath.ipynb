{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## zbMath"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## BLEU score between Reference formula and Candidate formula (converted using the Lucas-blecher tool)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BLEU score for reference formula:  \\mathrm{ð‹ð¨}, candidate formula:  \\mathrm{LO}\n",
      "BLEU score: 0.7558566433566434\n",
      "\n",
      "BLEU score for reference formula:  f^{2 \\cdot 2^q + 1}, candidate formula:  f^{2}\\cdot2^{q}+1\n",
      "BLEU score: 0.5053862912346019\n",
      "\n",
      "BLEU score for reference formula:  \\left\\{ \\left( u - k \\right)^{\\int_0^1 x^{u - 2k - 1} \\left(1 - x\\right)^k dx} \\circ x \\right\\}^{-1}, candidate formula:  \\left\\{(U-k)\\int_{0}^{1}x^{u-2k-1}(1-x)^{k}d x\\,\\circ\\,X\\right\\}-1\n",
      "BLEU score: 0.37726075795131636\n",
      "\n",
      "BLEU score for reference formula:  \\left( b - e - \\lim_{{t \\to 0^+}} \\left( \\frac{1}{{t^2}} \\left\\{ F_T \\left( (z, z^*) + t(v, v^*) \\right) - F_T (z, z^*) - t \\left( (v, v^*), (z, z^*) \\right) \\right\\} \\right) \\right) \\cdot (v, v^*), candidate formula:  \\left(b-\\mathrm{e}-\\operatorname*{lim}_{t\\rightarrow0^{+}}\\left(\\frac1t\\dot{\\prime}\\left(F_{T}((Z,Z^{*})+t(V,V^{*})\\right)-F_{T}(Z,Z^{*})-t((V,V^{*}),(Z,Z^{*})\\right)\\right)\\right)\\cdot\\cdot\\cdot(V,V^{*})\n",
      "BLEU score: 0.4226334311820454\n",
      "\n",
      "BLEU score for reference formula:  \\lim_{{a \\to 0}} \\left[ \\sup_{B:r_B \\leq a} \\left( \\frac{1}{{|B|}} \\int_B \\left( | \\left( I - e^{-r_B^2 \\cdot L} \\right) M \\right)^{\\frac{1}{2}} \\cdot f(x) \\, dx \\right) \\right]^{\\frac{1}{2}}, candidate formula:  \\left|\\frac{|{\\uparrow}\\Pi}{\\partial\\to0}\\right|_{B:r_{B}\\,\\leq\\varnothing}\\left(\\frac{1}{|B|}\\right)_{B}\\left(|\\left(l-\\Theta^{-r_{B}^{2}\\cdot L}\\right)M\\right)^{\\frac{1}{2}}\\cdot f(X)\\,Q X\\right)\\right|^{\\frac{1}{2}}\n",
      "BLEU score: 0.5378512885133403\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "import csv\n",
    "from collections import Counter\n",
    "\n",
    "# List of allowed built-in LaTeX functions\n",
    "allowed_functions = ['frac', 'sin', 'cos', 'tan', 'log', 'ln', 'sqrt', 'sum', 'cdot', 'left', 'right', 'circ', 'to', 'operatorname', 'rightarrow', 'dot','prime', \n",
    "                     'prod', 'lim', 'int', 'sigma', 'pi', 'mu', 'infty', 'mathrm', 'sup', 'leq', 'uparrow', 'partial', 'varnothing', 'Theta']\n",
    "\n",
    "def tokenize_formula(formula):\n",
    "    pattern = r\"\\\\([a-zA-Z]+)\"\n",
    "    \n",
    "    def replace_function(match):\n",
    "        function_name = match.group(1)\n",
    "        if function_name.lower() in [f.lower() for f in allowed_functions]:\n",
    "            return f\"@{function_name}@\"\n",
    "        else:\n",
    "            raise ValueError(f\"Invalid LaTeX command: {match.group(0)}\")\n",
    "    \n",
    "    formula = re.sub(pattern, replace_function, formula)\n",
    "    \n",
    "    return formula.lower()\n",
    "\n",
    "# Function to calculate BLEU score for LaTeX formulas\n",
    "def calculate_formula_bleu_score(reference_formula, candidate_formula, weights):\n",
    "    # Tokenize the formulas\n",
    "    ref_tokens = tokenize_formula(reference_formula)\n",
    "    cand_tokens = tokenize_formula(candidate_formula)\n",
    "\n",
    "    # Calculate n-gram precision\n",
    "    precisions = []\n",
    "    for n in range(1, len(weights) + 1):\n",
    "        ref_ngrams = [tuple(ref_tokens[i:i + n]) for i in range(len(ref_tokens) - n + 1)]\n",
    "        cand_ngrams = [tuple(cand_tokens[i:i + n]) for i in range(len(cand_tokens) - n + 1)]\n",
    "        ref_ngram_counts = Counter(ref_ngrams)\n",
    "        cand_ngram_counts = Counter(cand_ngrams)\n",
    "        common_ngram_counts = ref_ngram_counts & cand_ngram_counts\n",
    "        precision = sum(common_ngram_counts.values()) / sum(cand_ngram_counts.values())\n",
    "        precisions.append(precision)\n",
    "\n",
    "    # Calculate cumulative precision\n",
    "    cumulative_precision = sum(p * w for p, w in zip(precisions, weights))\n",
    "\n",
    "    # Calculate length penalty\n",
    "    reference_length = len(ref_tokens)\n",
    "    candidate_length = len(cand_tokens)\n",
    "    length_penalty = 1 if candidate_length >= reference_length else pow(2, 1 - reference_length / candidate_length)\n",
    "\n",
    "    # Calculate modified BLEU score\n",
    "    bleu_score = length_penalty * cumulative_precision\n",
    "\n",
    "    return bleu_score\n",
    "\n",
    "# Read CSV file and calculate BLEU score for each pair of formulas\n",
    "with open('evaluation_zbmath_lucas.csv', 'r') as csvfile:\n",
    "    csvreader = csv.reader(csvfile, delimiter=';')\n",
    "    next(csvreader)  # Skip header row if present\n",
    "    \n",
    "    for row in csvreader:\n",
    "        reference_formula = row[0]\n",
    "        candidate_formula = row[1]\n",
    "\n",
    "        weights = [0.25, 0.25, 0.25, 0.25]  # Equal weights for 1-gram, 2-gram, 3-gram, and 4-gram\n",
    "\n",
    "        bleu_score = calculate_formula_bleu_score(reference_formula, candidate_formula, weights)\n",
    "        print(f\"BLEU score for reference formula: {reference_formula}, candidate formula: {candidate_formula}\")\n",
    "        print(\"BLEU score:\", bleu_score)\n",
    "        print()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## BLEU score between Reference formula and Candidate formula (converted using MathPix tool)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BLEU score for reference formula:  \\mathrm{ð‹ð¨}, candidate formula:  \\text { Lo }\n",
      "BLEU score: 0.12637362637362637\n",
      "\n",
      "BLEU score for reference formula:  f^{2 \\cdot 2^q + 1}, candidate formula:  f^2 \\cdot 2^q+1\n",
      "BLEU score: 0.6772075419083671\n",
      "\n",
      "BLEU score for reference formula:  \\left\\{ \\left( u - k \\right)^{\\int_0^1 x^{u - 2k - 1} \\left(1 - x\\right)^k dx} \\circ x \\right\\}^{-1}, candidate formula:  \\left\\{(u-k)^{\\int_0^1 x^{u-2 k-1}(1-x)^k d x} \\circ x\\right\\}^{-1}\n",
      "BLEU score: 0.5423433176121712\n",
      "\n",
      "BLEU score for reference formula:  \\left( b - e - \\lim_{{t \\to 0^+}} \\left( \\frac{1}{{t^2}} \\left\\{ F_T \\left( (z, z^*) + t(v, v^*) \\right) - F_T (z, z^*) - t \\left( (v, v^*), (z, z^*) \\right) \\right\\} \\right) \\right) \\cdot (v, v^*), candidate formula:  \\left(b-e-\\lim _{t \\rightarrow 0^{+}}\\left(\\frac{1}{t^2}\\left\\{F_T\\left(\\left(z, z^*\\right)+t\\left(v, v^*\\right)\\right)-F_T\\left(z, z^*\\right)-t\\left(\\left(v, v^*\\right),\\left(z, z^*\\right)\\right)\\right\\}\\right)\\right) \\cdot\\left(v, v^*\\right)\n",
      "BLEU score: 0.4994904413533279\n",
      "\n",
      "BLEU score for reference formula:  \\lim_{{a \\to 0}} \\left[ \\sup_{B:r_B \\leq a} \\left( \\frac{1}{{|B|}} \\int_B \\left( | \\left( I - e^{-r_B^2 \\cdot L} \\right) M \\right)^{\\frac{1}{2}} \\cdot f(x) \\, dx \\right) \\right]^{\\frac{1}{2}}, candidate formula:  \\lim _{a \\rightarrow 0}\\left[\\sup _{B: r_B \\leq a}\\left(\\frac{1}{|B|} \\int_B\\left(\\mid\\left(I-e^{-r_B^2 \\cdot L}\\right) M\\right)^{\\frac{1}{2}} \\cdot f(x) d x\\right)\\right]^{\\frac{1}{2}}\n",
      "BLEU score: 0.768851580211948\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "import csv\n",
    "from collections import Counter\n",
    "\n",
    "# List of allowed built-in LaTeX functions\n",
    "allowed_functions = ['frac', 'sin', 'cos', 'tan', 'log', 'ln', 'sqrt', 'sum', 'cdot', 'left', 'right', 'circ', 'to', 'operatorname', 'rightarrow', 'dot','prime', \n",
    "                     'prod', 'lim', 'int', 'sigma', 'pi', 'mu', 'infty', 'mathrm', 'sup', 'leq', 'uparrow', 'partial', 'varnothing', 'Theta', 'text', 'mid']\n",
    "\n",
    "def tokenize_formula(formula):\n",
    "    pattern = r\"\\\\([a-zA-Z]+)\"\n",
    "    \n",
    "    def replace_function(match):\n",
    "        function_name = match.group(1)\n",
    "        if function_name.lower() in [f.lower() for f in allowed_functions]:\n",
    "            return f\"@{function_name}@\"\n",
    "        else:\n",
    "            raise ValueError(f\"Invalid LaTeX command: {match.group(0)}\")\n",
    "    \n",
    "    formula = re.sub(pattern, replace_function, formula)\n",
    "    \n",
    "    return formula.lower()\n",
    "\n",
    "# Function to calculate BLEU score for LaTeX formulas\n",
    "def calculate_formula_bleu_score(reference_formula, candidate_formula, weights):\n",
    "    # Tokenize the formulas\n",
    "    ref_tokens = tokenize_formula(reference_formula)\n",
    "    cand_tokens = tokenize_formula(candidate_formula)\n",
    "\n",
    "    # Calculate n-gram precision\n",
    "    precisions = []\n",
    "    for n in range(1, len(weights) + 1):\n",
    "        ref_ngrams = [tuple(ref_tokens[i:i + n]) for i in range(len(ref_tokens) - n + 1)]\n",
    "        cand_ngrams = [tuple(cand_tokens[i:i + n]) for i in range(len(cand_tokens) - n + 1)]\n",
    "        ref_ngram_counts = Counter(ref_ngrams)\n",
    "        cand_ngram_counts = Counter(cand_ngrams)\n",
    "        common_ngram_counts = ref_ngram_counts & cand_ngram_counts\n",
    "        precision = sum(common_ngram_counts.values()) / sum(cand_ngram_counts.values())\n",
    "        precisions.append(precision)\n",
    "\n",
    "    # Calculate cumulative precision\n",
    "    cumulative_precision = sum(p * w for p, w in zip(precisions, weights))\n",
    "\n",
    "    # Calculate length penalty\n",
    "    reference_length = len(ref_tokens)\n",
    "    candidate_length = len(cand_tokens)\n",
    "    length_penalty = 1 if candidate_length >= reference_length else pow(2, 1 - reference_length / candidate_length)\n",
    "\n",
    "    # Calculate modified BLEU score\n",
    "    bleu_score = length_penalty * cumulative_precision\n",
    "\n",
    "    return bleu_score\n",
    "\n",
    "# Read CSV file and calculate BLEU score for each pair of formulas\n",
    "with open('evaluation_zbmath_mathpix.csv', 'r') as csvfile:\n",
    "    csvreader = csv.reader(csvfile, delimiter=';')\n",
    "    next(csvreader)  # Skip header row if present\n",
    "    \n",
    "    for row in csvreader:\n",
    "        reference_formula = row[0]\n",
    "        candidate_formula = row[1]\n",
    "\n",
    "        weights = [0.25, 0.25, 0.25, 0.25]  # Equal weights for 1-gram, 2-gram, 3-gram, and 4-gram\n",
    "\n",
    "        bleu_score = calculate_formula_bleu_score(reference_formula, candidate_formula, weights)\n",
    "        print(f\"BLEU score for reference formula: {reference_formula}, candidate formula: {candidate_formula}\")\n",
    "        print(\"BLEU score:\", bleu_score)\n",
    "        print()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.6"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
